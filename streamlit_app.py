import streamlit as st
import pandas as pd
from transformers import pipeline, BertJapaneseTokenizer
import plotly.express as px
from wordcloud import WordCloud
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import io
import os

# unidicã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’try-exceptã§å›²ã‚€ï¼ˆã‚¨ãƒ©ãƒ¼æ™‚ã¯ç”»é¢ã«è¡¨ç¤ºã—ã¦å‡¦ç†åœæ­¢ï¼‰
try:
    import unidic
except Exception as e:
    st.error(f"unidicã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ:\n{e}")
    st.stop()


@st.cache_resource(show_spinner=False)
def load_sentiment_model():
    # MeCabè¾æ›¸ã®ãƒ‘ã‚¹ã‚’unidic-liteã‹ã‚‰å–å¾—
    mecab_dic_path = unidic.DICDIR
    tokenizer = BertJapaneseTokenizer.from_pretrained(
        "koheiduck/bert-japanese-finetuned-sentiment",
        mecab_kwargs={"mecab_args": f"-d {mecab_dic_path}"}
    )
    return pipeline(
        "sentiment-analysis",
        model="koheiduck/bert-japanese-finetuned-sentiment",
        tokenizer=tokenizer,
        return_all_scores=True,
    )


model = load_sentiment_model()

st.title("Sentia - é«˜ç²¾åº¦æ—¥æœ¬èªæ„Ÿæƒ…åˆ†æï¼ˆè¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«ï¼‹ã‚«ã‚¹ã‚¿ãƒ è¾æ›¸å¯¾å¿œï¼‹æ‹¡å¼µæ©Ÿèƒ½ï¼‰")

if "custom_dict" not in st.session_state:
    st.session_state.custom_dict = {}

st.sidebar.header("ã‚«ã‚¹ã‚¿ãƒ è¾æ›¸ç®¡ç†")

with st.sidebar.expander("ã‚«ã‚¹ã‚¿ãƒ è¾æ›¸ã®è¿½åŠ ãƒ»æ›´æ–°"):
    st.write("â–  å˜èªã‚’1ã¤ã ã‘è¿½åŠ ãƒ»æ›´æ–°")
    new_word = st.text_input("å˜èªã‚’å…¥åŠ›")
    new_score = st.selectbox("æ„Ÿæƒ…ãƒ©ãƒ™ãƒ«ã‚’é¸æŠ", ["ãƒã‚¸ãƒ†ã‚£ãƒ–", "ãƒã‚¬ãƒ†ã‚£ãƒ–", "ä¸­ç«‹"])
    if st.button("è¾æ›¸ã«è¿½åŠ ãƒ»æ›´æ–°"):
        if new_word:
            st.session_state.custom_dict[new_word] = new_score
            st.success(f"å˜èªã€Œ{new_word}ã€ã‚’è¾æ›¸ã«è¿½åŠ ãƒ»æ›´æ–°ã—ã¾ã—ãŸã€‚")

    st.write("---")
    st.write("â–  Excelãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ä¸€æ‹¬ç™»éŒ²ï¼ˆ1åˆ—ç›®: å˜èª, 2åˆ—ç›®: æ„Ÿæƒ…ãƒ©ãƒ™ãƒ«ï¼‰")
    dict_file = st.file_uploader("è¾æ›¸ç”¨Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["xlsx"], key="dict_uploader")
    if dict_file:
        try:
            df_dict = pd.read_excel(dict_file)
            added_count = 0
            for idx, row in df_dict.iterrows():
                word = str(row.iloc[0]).strip()
                label = str(row.iloc[1]).strip()
                if word and label in ["ãƒã‚¸ãƒ†ã‚£ãƒ–", "ãƒã‚¬ãƒ†ã‚£ãƒ–", "ä¸­ç«‹"]:
                    st.session_state.custom_dict[word] = label
                    added_count += 1
            st.success(f"{added_count}ä»¶ã®å˜èªã‚’ã‚«ã‚¹ã‚¿ãƒ è¾æ›¸ã«è¿½åŠ ãƒ»æ›´æ–°ã—ã¾ã—ãŸã€‚")
        except Exception as e:
            st.error(f"è¾æ›¸ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

with st.sidebar.expander("ã‚«ã‚¹ã‚¿ãƒ è¾æ›¸ã®è¡¨ç¤ºãƒ»æ¤œç´¢ãƒ»ç·¨é›†ãƒ»å‰Šé™¤"):
    search_query = st.text_input("ğŸ” å˜èªã§æ¤œç´¢")
    filtered_dict = {k: v for k, v in st.session_state.custom_dict.items() if search_query in k}

    for word, label in filtered_dict.items():
        cols = st.columns([4, 3, 2, 2])
        with cols[0]:
            new_key = f"edit_{word}"
            new_word_edit = st.text_input("å˜èª", word, key=new_key)
        with cols[1]:
            new_label_key = f"label_{word}"
            new_label = st.selectbox("ãƒ©ãƒ™ãƒ«", ["ãƒã‚¸ãƒ†ã‚£ãƒ–", "ãƒã‚¬ãƒ†ã‚£ãƒ–", "ä¸­ç«‹"], index=["ãƒã‚¸ãƒ†ã‚£ãƒ–", "ãƒã‚¬ãƒ†ã‚£ãƒ–", "ä¸­ç«‹"].index(label), key=new_label_key)
        with cols[2]:
            if st.button("æ›´æ–°", key=f"update_{word}"):
                del st.session_state.custom_dict[word]
                st.session_state.custom_dict[new_word_edit] = new_label
                st.success(f"ã€Œ{word}ã€ã‚’ã€Œ{new_word_edit}ã€ã«æ›´æ–°ã—ã¾ã—ãŸã€‚")
                st.experimental_rerun()
        with cols[3]:
            if st.button("å‰Šé™¤", key=f"delete_{word}"):
                if st.session_state.get("confirm_delete") == word:
                    del st.session_state.custom_dict[word]
                    st.success(f"å˜èªã€Œ{word}ã€ã‚’å‰Šé™¤ã—ã¾ã—ãŸã€‚")
                    st.session_state.confirm_delete = None
                    st.experimental_rerun()
                else:
                    st.session_state.confirm_delete = word
                    st.warning(f"âš ï¸ æœ¬å½“ã«ã€Œ{word}ã€ã‚’å‰Šé™¤ã—ã¾ã™ã‹ï¼Ÿ ã‚‚ã†ä¸€åº¦å‰Šé™¤ã‚’æŠ¼ã™ã¨ç¢ºå®šã—ã¾ã™ã€‚")

# --- ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ ---
uploaded_files = st.file_uploader("Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["xlsx"], accept_multiple_files=True)

label_map = {
    "POSITIVE": "ãƒã‚¸ãƒ†ã‚£ãƒ–",
    "NEGATIVE": "ãƒã‚¬ãƒ†ã‚£ãƒ–",
    "NEUTRAL": "ä¸­ç«‹"
}

if uploaded_files:
    for uploaded_file in uploaded_files:
        df = pd.read_excel(uploaded_file)
        st.subheader(f"ãƒ•ã‚¡ã‚¤ãƒ«: {uploaded_file.name}")

        selected_col = st.selectbox(f"åˆ†æã™ã‚‹åˆ—ã‚’é¸æŠ ({uploaded_file.name})", df.columns, key=f"select_col_{uploaded_file.name}")
        date_col = st.selectbox(f"ï¼ˆä»»æ„ï¼‰æ—¥ä»˜åˆ—ã‚’é¸æŠ ({uploaded_file.name})", [None] + list(df.columns), key=f"date_col_{uploaded_file.name}")

        def apply_custom_dictionary(text):
            if not isinstance(text, str): return None
            for word, label in st.session_state.custom_dict.items():
                if word in text:
                    return label
            return None

        result_key = f"result_{uploaded_file.name}"
        analyze_button_key = f"analyze_btn_{uploaded_file.name}"

        if st.button(f"{uploaded_file.name} ã‚’åˆ†æé–‹å§‹", key=analyze_button_key):
            with st.spinner("åˆ†æä¸­..."):
                texts = df[selected_col].astype(str)
                custom_labels = texts.apply(apply_custom_dictionary)
                to_analyze = custom_labels.isna()
                raw_results = model(texts[to_analyze].tolist(), batch_size=16)
                predicted_labels = [max(scores, key=lambda x: x['score']) for scores in raw_results]

                df.loc[to_analyze, "æ„Ÿæƒ…åˆ¤å®š"] = [label_map[res['label']] for res in predicted_labels]
                df.loc[to_analyze, "ã‚¹ã‚³ã‚¢"] = [res['score'] for res in predicted_labels]
                df.loc[~to_analyze, "æ„Ÿæƒ…åˆ¤å®š"] = custom_labels[~to_analyze]
                df.loc[~to_analyze, "ã‚¹ã‚³ã‚¢"] = 1.0

                st.session_state[result_key] = df

        if result_key in st.session_state:
            df = st.session_state[result_key]

            st.write("### æ„Ÿæƒ…åˆ†å¸ƒ")
            fig = px.pie(
                df,
                names="æ„Ÿæƒ…åˆ¤å®š",
                title="æ„Ÿæƒ…å†…è¨³",
                color="æ„Ÿæƒ…åˆ¤å®š",
                color_discrete_map={
                    "ãƒã‚¸ãƒ†ã‚£ãƒ–": "#2ecc71",  # ç·‘ç³»
                    "ãƒã‚¬ãƒ†ã‚£ãƒ–": "#e74c3c",  # èµ¤ç³»
                    "ä¸­ç«‹": "#95a5a6",       # ã‚°ãƒ¬ãƒ¼ç³»
                },
            )
            st.plotly_chart(fig, use_container_width=True)

            def plot_wordcloud(texts, title):
                if len(texts) == 0:
                    st.write(f"{title} ã®ãƒ†ã‚­ã‚¹ãƒˆãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
                    return
                text_all = ' '.join(texts)
                font_path = '/System/Library/Fonts/ãƒ’ãƒ©ã‚®ãƒè§’ã‚´ã‚·ãƒƒã‚¯ W5.ttc'
                wordcloud = WordCloud(
                    font_path=font_path,
                    background_color='white',
                    width=800,
                    height=400
                ).generate(text_all)

                font_prop = fm.FontProperties(fname=font_path)

                buf = io.BytesIO()
                plt.figure(figsize=(10, 5))
                plt.imshow(wordcloud, interpolation='bilinear')
                plt.axis("off")
                plt.title(title, fontproperties=font_prop)
                plt.tight_layout()
                plt.savefig(buf, format='png')
                plt.close()
                st.image(buf)

            st.write("### ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰")
            for emotion in ["ãƒã‚¸ãƒ†ã‚£ãƒ–", "ãƒã‚¬ãƒ†ã‚£ãƒ–", "ä¸­ç«‹"]:
                filtered = df[df["æ„Ÿæƒ…åˆ¤å®š"] == emotion][selected_col].dropna()
                plot_wordcloud(filtered.tolist(), f"{emotion} ã®ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰")

            if date_col and date_col in df.columns:
                st.write("### æ„Ÿæƒ…ã®æ™‚ç³»åˆ—æ¨ç§»")
                df[date_col] = pd.to_datetime(df[date_col], errors='coerce')
                time_df = (
                    df.dropna(subset=[date_col])
                      .groupby([df[date_col].dt.date, "æ„Ÿæƒ…åˆ¤å®š"])
                      .size()
                      .reset_index(name="ä»¶æ•°")
                )
                fig_line = px.line(
                    time_df,
                    x=date_col,
                    y="ä»¶æ•°",
                    color="æ„Ÿæƒ…åˆ¤å®š",
                    title="æ„Ÿæƒ…ã®æ™‚ç³»åˆ—æ¨ç§»"
                )
                st.plotly_chart(fig_line, use_container_width=True)

            st.write("### æŠœç²‹ã‚µãƒ³ãƒ—ãƒ«")
            for emotion in ["ãƒã‚¸ãƒ†ã‚£ãƒ–", "ãƒã‚¬ãƒ†ã‚£ãƒ–", "ä¸­ç«‹"]:
                st.markdown(f"#### {emotion}ã®ä¾‹")
                examples = df[df["æ„Ÿæƒ…åˆ¤å®š"] == emotion][selected_col].dropna()
                if len(examples) == 0:
                    st.write("ä¾‹ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
                else:
                    samples = examples.sample(n=min(3, len(examples)), random_state=42)
                    for text in samples:
                        with st.expander(text[:50] + "..."):
                            st.write(text)

            st.write("### çµã‚Šè¾¼ã¿æ©Ÿèƒ½")
            filter_label = st.selectbox("æ„Ÿæƒ…ã§ãƒ•ã‚£ãƒ«ã‚¿", ["ã™ã¹ã¦", "ãƒã‚¸ãƒ†ã‚£ãƒ–", "ãƒã‚¬ãƒ†ã‚£ãƒ–", "ä¸­ç«‹"], key=f"filter_label_{uploaded_file.name}")
            filter_score = st.slider("ã‚¹ã‚³ã‚¢ãŒã“ã®å€¤ä»¥ä¸Šã®ãƒ‡ãƒ¼ã‚¿ã®ã¿è¡¨ç¤º", 0.0, 1.0, 0.0, 0.01, key=f"filter_score_{uploaded_file.name}")

            filtered_df = df[df["ã‚¹ã‚³ã‚¢"] >= filter_score]
            if filter_label != "ã™ã¹ã¦":
                filtered_df = filtered_df[filtered_df["æ„Ÿæƒ…åˆ¤å®š"] == filter_label]

            st.dataframe(filtered_df)

            st.download_button(
                "CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=filtered_df.to_csv(index=False).encode("utf-8-sig"),
                file_name=f"{uploaded_file.name}_result.csv",
                mime="text/csv"
            )
else:
    st.info("Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚â€»è¤‡æ•°å¯")
